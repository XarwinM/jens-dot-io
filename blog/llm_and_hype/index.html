<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jens Müller">
<meta name="dcterms.date" content="2025-08-11">
<meta name="description" content="LLMs have the potential to become extraordinarily powerful, but they also face inherent limitations. This article explores both their vast capabilities and the challenges they encounter.">

<title>Hype or Underrated: LLMs and Their True Capabilities – Jens Müller</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(../../img/background.png);
background-size: cover;
      }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta name="twitter:title" content="Hype or Underrated: LLMs and Their True Capabilities – Jens Müller">
<meta name="twitter:description" content="LLMs have the potential to become extraordinarily powerful, but they also face inherent limitations. This article explores both their vast capabilities and the challenges they encounter.">
<meta name="twitter:image" content="https://www.jensmueller.io/blog/llm_and_hype/iceberg.png">
<meta name="twitter:image-height" content="1024">
<meta name="twitter:image-width" content="1536">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Jens Müller</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../projects/index.html"> 
<span class="menu-text">Projects</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../blog/index.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default blog-post page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <div class="quarto-title-block"><div><h1 class="title">Hype or Underrated: LLMs and Their True Capabilities</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
                  <div>
        <div class="description">
          LLMs have the potential to become extraordinarily powerful, but they also face inherent limitations. This article explores both their vast capabilities and the challenges they encounter.
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">AI</div>
                <div class="quarto-category">LLM</div>
                <div class="quarto-category">Future</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p><a href="https://jensmueller.io/">Jens Müller</a> </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">August 11, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#llms-and-their-abilities" id="toc-llms-and-their-abilities" class="nav-link active" data-scroll-target="#llms-and-their-abilities">LLMs and their Abilities</a>
  <ul class="collapse">
  <li><a href="#requirementspremises" id="toc-requirementspremises" class="nav-link" data-scroll-target="#requirementspremises">Requirements/Premises</a></li>
  <li><a href="#the-possibilities" id="toc-the-possibilities" class="nav-link" data-scroll-target="#the-possibilities">The Possibilities</a></li>
  <li><a href="#limits-and-challenges" id="toc-limits-and-challenges" class="nav-link" data-scroll-target="#limits-and-challenges">Limits and Challenges</a>
  <ul class="collapse">
  <li><a href="#words-miss-details" id="toc-words-miss-details" class="nav-link" data-scroll-target="#words-miss-details">Words miss details</a></li>
  <li><a href="#generating-new-knowledge" id="toc-generating-new-knowledge" class="nav-link" data-scroll-target="#generating-new-knowledge">Generating new knowledge</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#conclusion-and-discussion" id="toc-conclusion-and-discussion" class="nav-link" data-scroll-target="#conclusion-and-discussion">Conclusion and Discussion</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">
<div class="no-row-height column-margin column-container">
    <div class="">
      <img src="iceberg.png" style="width:100%">
    </div>
  </div>





<section id="llms-and-their-abilities" class="level1 page-columns page-full">
<h1>LLMs and their Abilities</h1>
<p>Speculation about the potential of LLMs has created a divide. Some view their promise as overhyped, already descending the slope of Gartner’s Hype Cycle. Others believe their potential is far from fully realized. Within the latter camp, opinions vary: some argue that LLMs are fundamentally constrained by human intelligence, as they are trained on human-generated data. Others contend that these models may surpass human-level intelligence, unlocking capabilities beyond our current understanding.</p>
<p>Technically, LLMs are pretrained to predict the next token from preceding ones, then often refined using methods like reinforcement learning.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> How far can this process take us?</p>
<div class="no-row-height column-margin column-container"><div id="fn1"><p><sup>1</sup>&nbsp;For a more comprehensive overview that explains the training procedure have a look <a href="https://masteringllm.medium.com/llm-training-a-simple-3-step-guide-you-wont-find-anywhere-else-98ee218809e5">here</a></p></div></div><section id="requirementspremises" class="level2">
<h2 class="anchored" data-anchor-id="requirementspremises">Requirements/Premises</h2>
<p>Before analyzing the potential strengths and limitations of LLMs, it is essential to clarify the underlying premises. We pose two simplifying assumptions:</p>
<section id="weak-extrapolation-capabilities" class="level4">
<h4 class="anchored" data-anchor-id="weak-extrapolation-capabilities"><em>Weak</em> extrapolation Capabilities</h4>
<p>The primary assumption is that the model has the capability to <em>combine</em>. For example, if the model is trained on crime novels and children’s fairy tales, we expect it to generate a hybrid story blending elements from both genres — a crime-themed fairy tale. This is related to the term of extrapolation and interpolation in mathematics.</p>
</section>
<section id="effective-search" class="level4">
<h4 class="anchored" data-anchor-id="effective-search">Effective Search</h4>
<p>Since an LLM generates text token by token, errors may accumulate over time and we might miss the optimal solution (as discussed <a href="https://jensmueller.io/blog/how_to_sample/index.html">here</a>). Therefore, we assume that the search process remains effective, even when the language model produces longer texts.</p>
</section>
</section>
<section id="the-possibilities" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="the-possibilities">The Possibilities</h2>
<p>The potential of LLMs is already vast, and new frontiers, such as agentic workflows, are continually emerging. Let’s take a closer look at the underlying causes that drive these powerful models.</p>
<section id="llms-can-act" class="level4">
<h4 class="anchored" data-anchor-id="llms-can-act">1. LLMs can act</h4>
<p>What the LLM produces is not only, it can affect the world. While humans have hands to influence the world, an LLM could select from a list of tools, to act upon in the world. A simple example is producing a chat message capable of persuading a human to take a specific action. On a more advanced level, an LLM could query information with high efficiency and then act on that knowledge—such as buying stocks, optimizing business processes, or even starting a company.</p>
<p>This transformation from text to action relies on a critical intermediary: a system or parser that translates meaningful text outputs into actionable commands, like function calls. With such a setup, the LLM’s potential expands dramatically, enabling it to interact with and reshape the world in ways limited only by the tools and frameworks available to it.</p>
</section>
<section id="the-power-comes-from-combination" class="level4">
<h4 class="anchored" data-anchor-id="the-power-comes-from-combination">2. The power comes from Combination</h4>
<p>Ultimately, the goal is to craft a story in as much detail as possible for an LLM to act effectively in the world. This story functions like an ongoing dialogue, encompassing both the states of the world and the LLM’s responses. For instance, a company founding scenario could involve a dynamically evolving script that integrates reality-based elements (not authored by the LLM) with sections generated by the LLM containing actionable instructions. These action-instructions would then be interpreted and executed by a parser, as previously described.</p>
<p>Since history never repeats exactly, the LLM must combine prior knowledge in order to operate effectively in new and unfamiliar situations.</p>
</section>
<section id="conditioning-allows-above-dataset-performance" class="level4">
<h4 class="anchored" data-anchor-id="conditioning-allows-above-dataset-performance">3. Conditioning allows above-dataset performance</h4>
<p>While a training dataset might primarily consist of average written text, it also includes examples of far-above-average quality. Prompting a model serves as a form of conditioning, enabling us to guide the model toward generating content that reflects specific standards.</p>
<p>For example, by prompting the model to respond in the style of <em>Goethe</em> or <em>Schiller</em>, we effectively request output that aligns with the eloquence, depth, and poetic quality characteristic of such literary giants. If the model adheres to the prompt, it can produce text that significantly surpasses average quality — in this example from a poetic and stylistic perspective.</p>
</section>
<section id="fast-execution" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="fast-execution">4. Fast execution</h4>
<p>Let’s assume that humans read at an average speed of 300 words per minute, while models generate approximately 10 tokens per second, or 600 tokens per minute. Suppose that, on average, 1.3 tokens correspond to one word <a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a>, this translates to roughly <span class="math inline">\(\frac{600}{1.3} \approx 461\)</span> words generated per minute by the model.</p>
<div class="no-row-height column-margin column-container"><div id="fn2"><p><sup>2</sup>&nbsp;for an estimate see <a href="https://github.com/ray-project/llm-numbers">here</a></p></div></div><p>This estimate is somewhat conservative: the average human reading speed is often lower than 300 words per minute, and the model’s generation speed of 10 tokens per second might also be on the lower side. To put it more dramatically, a large language model (LLM) could operate faster than we can process. This speed might set an LLM on a different stage compared to a human when it is about creating content or even acting in the world.</p>
<p>Computers often seem like magical machines capable of incredible feats. This <em>magic</em> stems from their extraordinary ability to execute vast numbers of simple operations with astonishing speed, enabling the emergence of highly complex systems. At the most fundamental level, basic operations like NAND (Not-AND) gates serve as the essential building blocks of computation, forming the foundation for arithmetic, logic circuits, and even the execution of sophisticated programs. At a slightly higher level, the rapid execution of linear operations paired with non-linearities powers neural networks, enabling them to learn, adapt, and make decisions. Speculatively, at even higher levels, LLMs might generate increasingly abstract actions, unlocking entirely new dimensions of <em>magic</em> in their capabilities. While much of this higher-level potential remains speculative, it signals exciting and transformative possibilities for the future.</p>
</section>
</section>
<section id="limits-and-challenges" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="limits-and-challenges">Limits and Challenges</h2>
<p>We hinted at the power of LLMs to craft dynamically evolving stories — akin to a real-time film script that interacts with and influences the world. In this scenario, the LLM takes on the role of one actor, performing actions within the script and, in doing so, shaping all subsequent events.</p>
<p>While we have alluded to the immense potential of this agent, a critical question remains: just how powerful is this actor? Without a doubt, there are limitations to what this agent can achieve.</p>
<section id="words-miss-details" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="words-miss-details">Words miss details</h3>
<section id="acting-in-the-world" class="level4">
<h4 class="anchored" data-anchor-id="acting-in-the-world">Acting in the World</h4>
<p>A book about juggling can provide an overview of throwing patterns, but it falls short of capturing the intricate details of the craft. While patterns like the cascade or shower may be described, the real complexity lies in the precise mechanics of juggling: the exact trajectory of each throw, the required force, and the precise timing of each movement. These subtle yet critical elements are absent, making the explanation too abstract to fully convey the nuanced coordination and skill involved in juggling.</p>
<p>Juggling is just one example, but almost any art or skill that involves real-world dynamics cannot be exhaustively captured in a book — making such skills inherently inaccessible to LLMs in a direct sense. Moreover, LLMs operate through tokens, and translating these tokens into physical actions, like juggling, poses a significant challenge. While these skills may not be directly accessible to an LLM, they could be indirectly leveraged. For instance, an LLM could delegate tasks by sending instructions or allocating resources—such as paying someone to perform juggling or crafting a complex wooden toy. This highlights the potential of LLMs to influence real-world activities indirectly through intermediaries, expanding their impact beyond the digital realm.</p>
<p>However, there are a few domains where all details are fully described through language, and one particularly intriguing example is <em>programming</em>. Code, by its nature, is entirely described in a structured linguistic form. Additionally, comments embedded in code offer valuable context, bridging the gap between natural language and the code itself.</p>
<p>From an economic perspective, the value attributed to code creation and maintenance is immense, representing a significant portion of technological investments. A super-powerful LLM, capable of excelling in this domain, could potentially claim a share of this value which translates to <em>money</em>. Access to money would dramatically extend the capacities of an LLM to even use <em>humans as tools</em>.</p>
</section>
<section id="understanding-the-world" class="level4 page-columns page-full">
<h4 class="anchored" data-anchor-id="understanding-the-world">Understanding the World</h4>
<p>Since an LLM based agent can in theory get access to money via their expertise field (e.g.&nbsp;programming), they have a sheer unlimited amount of tools at their hand - basically each human on earth can become a tool and being payed by the agent for their work. However, the question is can this agent act and strategize in the world. While we have no clear answer to this right now, there is indication that LLM can<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn3"><p><sup>3</sup>&nbsp;see for instance <a href="https://arxiv.org/abs/2507.02618">here</a></p></div></div></section>
</section>
<section id="generating-new-knowledge" class="level3 page-columns page-full">
<h3 class="anchored" data-anchor-id="generating-new-knowledge">Generating new knowledge</h3>
<p>An objection often raised about LLMs is the claim that they cannot generate new knowledge but merely reiterate or synthesize information present in their training data. If true, this would reduce LLMs to the role of an advanced search engine.</p>
<p>However, even at the level of reformulation, LLMs demonstrate a degree of creativity. For instance, rephrasing an invitation in pirate slang - what LLMs are very capable of - introduces novelty from a stylistic or expressive perspective. What critics typically mean by the inability to generate new knowledge often refers to new insights or discoveries that were not explicitly encoded in the training data.</p>
<p>Assessing this claim is challenging because verifying the semantic originality of LLM outputs requires searching not just for verbatim matches but also for conceptual equivalents across the vast corpus of training data. Nevertheless, there is evidence suggesting that LLMs can generate ideas that experts regard as novel, particularly in fields such as research <a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</p>
<div class="no-row-height column-margin column-container"><div id="fn4"><p><sup>4</sup>&nbsp;see for instance <a href="https://arxiv.org/abs/2409.04109">here</a></p></div></div><p>From a theoretical standpoint, LLMs have the potential to generate insights that apply to reality by synthesizing and combining information in ways not explicitly present in the training data. Consider a simplified scenario: the model identifies a paper describing a bacterium’s chemical pathways and another discussing a drug that inhibits a specific element in that pathway. If the LLM appropriately combines these pieces of information, it could suggest a novel application for the drug, such as targeting the bacterium. This type of LLM-insight demonstrates how LLMs might contribute to the generation of actionable knowledge.</p>
</section>
</section>
</section>
<section id="conclusion-and-discussion" class="level1">
<h1>Conclusion and Discussion</h1>
<p>LLMs hold significant potential to function as autonomous agents in the real world. Limitations in certain areas can be offset by integrating specialized tools that already excel in those domains. In particular, access to financial resources could enable an LLM to expand its capabilities into the full spectrum of human skills and knowledge.</p>
<p>While some argue that new high-quality data will become scarce, the methods for training LLMs will continue to evolve. Approaches such as reinforcement learning and human-in-the-loop training can still generate substantial amounts of valuable training data. Moreover, data produced collaboratively by humans and LLMs may prove useful, and we may see an increasing abundance of such hybrid datasets.</p>
<p>Finally, advancements in reinforcement learning and related techniques have the potential to further enhance LLMs’ abilities in reasoning, strategy, and logical thinking, bringing them closer to truly autonomous and adaptable agents.</p>
<p>The scope of LLM research is vast, and we have addressed only a small portion of it — omitting, for example, multimodal models. In my view the potential of LLMs is far from fully realized, and significant advancements are likely to emerge in the near future.</p>


<!-- -->

</section>


</main> <!-- /main -->

<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/www\.jensmueller\.io");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://giscus.app/client.js" data-repo="XarwinM/jens-dot-io" data-repo-id="R_kgDONdpGrg" data-category="Announcements" data-category-id="DIC_kwDONdpGrs4ClOl3" data-mapping="title" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="bottom" data-theme="light" data-lang="en" crossorigin="anonymous" data-loading="lazy" async="">
</script>
<input type="hidden" id="giscus-base-theme" value="light">
<input type="hidden" id="giscus-alt-theme" value="dark"><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Hype or Underrated: LLMs and Their True Capabilities"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="an">description:</span><span class="co"> "LLMs have the potential to become extraordinarily powerful, but they also face inherent limitations. This article explores both their vast capabilities and the challenges they encounter."</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> 08-11-2025</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="an">categories:</span><span class="co"> </span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">  - AI </span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">  - LLM</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">  - Future</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="an">image:</span><span class="co"> iceberg.png</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co">    fig-cap-location: bottom</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">    include-before-body: ../../html/margin_image.html</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="an">draft:</span><span class="co"> false</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="an">twitter-card:</span><span class="co"> </span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co">  image: "iceberg.png"</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="fu"># LLMs and their Abilities</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>Speculation about the potential of LLMs has created a divide. Some view their promise as overhyped, already descending the slope of Gartner’s Hype Cycle. Others believe their potential is far from fully realized. Within the latter camp, opinions vary: some argue that LLMs are fundamentally constrained by human intelligence, as they are trained on human-generated data. Others contend that these models may surpass human-level intelligence, unlocking capabilities beyond our current understanding.</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>Technically, LLMs are pretrained to predict the next token from preceding ones, then often refined using methods like reinforcement learning.^<span class="co">[</span><span class="ot">For a more comprehensive overview that explains the training procedure have a look [here](https://masteringllm.medium.com/llm-training-a-simple-3-step-guide-you-wont-find-anywhere-else-98ee218809e5)</span><span class="co">]</span> How far can this process take us?</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="fu">## Requirements/Premises </span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>Before analyzing the potential strengths and limitations of LLMs, it is essential to clarify the underlying premises. We pose two simplifying assumptions:</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="fu">#### *Weak* extrapolation Capabilities </span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>The primary assumption is that the model has the capability to *combine*. For example, if the model is trained on crime novels and children’s fairy tales, we expect it to generate a hybrid story blending elements from both genres — a crime-themed fairy tale. This is related to the term of extrapolation and interpolation in mathematics.</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Effective Search </span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>Since an LLM generates text token by token, errors may accumulate over time and we might miss the optimal solution (as discussed <span class="co">[</span><span class="ot">here</span><span class="co">](https://jensmueller.io/blog/how_to_sample/index.html)</span>). Therefore, we assume that the search process remains effective, even when the language model produces longer texts.</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## The Possibilities</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>The potential of LLMs is already vast, and new frontiers, such as agentic workflows, are continually emerging. Let’s take a closer look at the underlying causes that drive these powerful models.</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. LLMs can act</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>What the LLM produces is not only, it can affect the world. While humans have hands to influence the world, an LLM could select from a list of tools, to act upon in the world. A simple example is producing a chat message capable of persuading a human to take a specific action. On a more advanced level, an LLM could query information with high efficiency and then act on that knowledge—such as buying stocks, optimizing business processes, or even starting a company.</span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>This transformation from text to action relies on a critical intermediary: a system or parser that translates meaningful text outputs into actionable commands, like function calls. With such a setup, the LLM’s potential expands dramatically, enabling it to interact with and reshape the world in ways limited only by the tools and frameworks available to it.</span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 2. The power comes from Combination</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>Ultimately, the goal is to craft a story in as much detail as possible for an LLM to act effectively in the world. This story functions like an ongoing dialogue, encompassing both the states of the world and the LLM’s responses. For instance, a company founding scenario could involve a dynamically evolving script that integrates reality-based elements (not authored by the LLM) with sections generated by the LLM containing actionable instructions. These action-instructions would then be interpreted and executed by a parser, as previously described. </span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>Since history never repeats exactly, the LLM must combine prior knowledge in order to operate effectively in new and unfamiliar situations.</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 3. Conditioning allows above-dataset performance</span></span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a>While a training dataset might primarily consist of average written text, it also includes examples of far-above-average quality. Prompting a model serves as a form of conditioning, enabling us to guide the model toward generating content that reflects specific standards. </span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a>For example, by prompting the model to respond in the style of *Goethe* or *Schiller*, we effectively request output that aligns with the eloquence, depth, and poetic quality characteristic of such literary giants. If the model adheres to the prompt, it can produce text that significantly surpasses average quality — in this example from a poetic and stylistic perspective. </span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 4. Fast execution</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a>Let’s assume that humans read at an average speed of 300 words per minute, while models generate approximately 10 tokens per second, or 600 tokens per minute. Suppose that, on average, 1.3 tokens correspond to one word ^<span class="co">[</span><span class="ot">for an estimate see [here](https://github.com/ray-project/llm-numbers)</span><span class="co">]</span>, this translates to roughly $\frac{600}{1.3} \approx 461$ words generated per minute by the model.</span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a>This estimate is somewhat conservative: the average human reading speed is often lower than 300 words per minute, and the model’s generation speed of 10 tokens per second might also be on the lower side. To put it more dramatically, a large language model (LLM) could operate faster than we can process. This speed might set an LLM on a different stage compared to a human when it is about creating content or even acting in the world. </span>
<span id="cb1-65"><a href="#cb1-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-66"><a href="#cb1-66" aria-hidden="true" tabindex="-1"></a>Computers often seem like magical machines capable of incredible feats. This *magic* stems from their extraordinary ability to execute vast numbers of simple operations with astonishing speed, enabling the emergence of highly complex systems.</span>
<span id="cb1-67"><a href="#cb1-67" aria-hidden="true" tabindex="-1"></a>At the most fundamental level, basic operations like NAND (Not-AND) gates serve as the essential building blocks of computation, forming the foundation for arithmetic, logic circuits, and even the execution of sophisticated programs. At a slightly higher level, the rapid execution of linear operations paired with non-linearities powers neural networks, enabling them to learn, adapt, and make decisions. Speculatively, at even higher levels, LLMs might generate increasingly abstract actions, unlocking entirely new dimensions of *magic* in their capabilities. While much of this higher-level potential remains speculative, it signals exciting and transformative possibilities for the future.</span>
<span id="cb1-68"><a href="#cb1-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-69"><a href="#cb1-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-70"><a href="#cb1-70" aria-hidden="true" tabindex="-1"></a><span class="fu">## Limits and Challenges </span></span>
<span id="cb1-71"><a href="#cb1-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-72"><a href="#cb1-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-73"><a href="#cb1-73" aria-hidden="true" tabindex="-1"></a>We hinted at the power of LLMs to craft dynamically evolving stories — akin to a real-time film script that interacts with and influences the world. In this scenario, the LLM takes on the role of one actor, performing actions within the script and, in doing so, shaping all subsequent events.</span>
<span id="cb1-74"><a href="#cb1-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-75"><a href="#cb1-75" aria-hidden="true" tabindex="-1"></a>While we have alluded to the immense potential of this agent, a critical question remains: just how powerful is this actor? Without a doubt, there are limitations to what this agent can achieve.</span>
<span id="cb1-76"><a href="#cb1-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-77"><a href="#cb1-77" aria-hidden="true" tabindex="-1"></a><span class="fu">### Words miss details </span></span>
<span id="cb1-78"><a href="#cb1-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-79"><a href="#cb1-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-80"><a href="#cb1-80" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Acting in the World</span></span>
<span id="cb1-81"><a href="#cb1-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-82"><a href="#cb1-82" aria-hidden="true" tabindex="-1"></a>A book about juggling can provide an overview of throwing patterns, but it falls short of capturing the intricate details of the craft. While patterns like the cascade or shower may be described, the real complexity lies in the precise mechanics of juggling: the exact trajectory of each throw, the required force, and the precise timing of each movement. These subtle yet critical elements are absent, making the explanation too abstract to fully convey the nuanced coordination and skill involved in juggling.</span>
<span id="cb1-83"><a href="#cb1-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-84"><a href="#cb1-84" aria-hidden="true" tabindex="-1"></a>Juggling is just one example, but almost any art or skill that involves real-world dynamics cannot be exhaustively captured in a book — making such skills inherently inaccessible to LLMs in a direct sense. Moreover, LLMs operate through tokens, and translating these tokens into physical actions, like juggling, poses a significant challenge.</span>
<span id="cb1-85"><a href="#cb1-85" aria-hidden="true" tabindex="-1"></a>While these skills may not be directly accessible to an LLM, they could be indirectly leveraged. For instance, an LLM could delegate tasks by sending instructions or allocating resources—such as paying someone to perform juggling or crafting a complex wooden toy. This highlights the potential of LLMs to influence real-world activities indirectly through intermediaries, expanding their impact beyond the digital realm.</span>
<span id="cb1-86"><a href="#cb1-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-87"><a href="#cb1-87" aria-hidden="true" tabindex="-1"></a>However, there are a few domains where all details are fully described through language, and one particularly intriguing example is *programming*. Code, by its nature, is entirely described in a structured linguistic form. Additionally, comments embedded in code offer valuable context, bridging the gap between natural language and the code itself.</span>
<span id="cb1-88"><a href="#cb1-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-89"><a href="#cb1-89" aria-hidden="true" tabindex="-1"></a>From an economic perspective, the value attributed to code creation and maintenance is immense, representing a significant portion of technological investments. A super-powerful LLM, capable of excelling in this domain, could potentially claim a share of this value which translates to *money*. Access to money would dramatically extend the capacities of an LLM to even use *humans as tools*.</span>
<span id="cb1-90"><a href="#cb1-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-91"><a href="#cb1-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-92"><a href="#cb1-92" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Understanding the World</span></span>
<span id="cb1-93"><a href="#cb1-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-94"><a href="#cb1-94" aria-hidden="true" tabindex="-1"></a>Since an LLM based agent can in theory get access to money via their expertise field (e.g. programming), they have a sheer unlimited amount of tools at their hand - basically each human on earth can become a tool and being payed by the agent for their work. However, the question is can this agent act and strategize in the world. While we have no clear answer to this right now, there is indication that LLM can^<span class="co">[</span><span class="ot">see for instance [here](https://arxiv.org/abs/2507.02618)</span><span class="co">]</span>.</span>
<span id="cb1-95"><a href="#cb1-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-96"><a href="#cb1-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-97"><a href="#cb1-97" aria-hidden="true" tabindex="-1"></a><span class="fu">### Generating new knowledge</span></span>
<span id="cb1-98"><a href="#cb1-98" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-99"><a href="#cb1-99" aria-hidden="true" tabindex="-1"></a>An objection often raised about LLMs is the claim that they cannot generate new knowledge but merely reiterate or synthesize information present in their training data. If true, this would reduce LLMs to the role of an advanced search engine.</span>
<span id="cb1-100"><a href="#cb1-100" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-101"><a href="#cb1-101" aria-hidden="true" tabindex="-1"></a>However, even at the level of reformulation, LLMs demonstrate a degree of creativity. For instance, rephrasing an invitation in pirate slang - what LLMs are very capable of - introduces novelty from a stylistic or expressive perspective. What critics typically mean by the inability to generate new knowledge often refers to new insights or discoveries that were not explicitly encoded in the training data.</span>
<span id="cb1-102"><a href="#cb1-102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-103"><a href="#cb1-103" aria-hidden="true" tabindex="-1"></a>Assessing this claim is challenging because verifying the semantic originality of LLM outputs requires searching not just for verbatim matches but also for conceptual equivalents across the vast corpus of training data. Nevertheless, there is evidence suggesting that LLMs can generate ideas that experts regard as novel, particularly in fields such as research ^<span class="co">[</span><span class="ot">see for instance [here](https://arxiv.org/abs/2409.04109)</span><span class="co">]</span>.</span>
<span id="cb1-104"><a href="#cb1-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-105"><a href="#cb1-105" aria-hidden="true" tabindex="-1"></a>From a theoretical standpoint, LLMs have the potential to generate insights that apply to reality by synthesizing and combining information in ways not explicitly present in the training data. Consider a simplified scenario: the model identifies a paper describing a bacterium’s chemical pathways and another discussing a drug that inhibits a specific element in that pathway. If the LLM appropriately combines these pieces of information, it could suggest a novel application for the drug, such as targeting the bacterium. This type of LLM-insight demonstrates how LLMs might contribute to the generation of actionable knowledge.</span>
<span id="cb1-106"><a href="#cb1-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-107"><a href="#cb1-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-108"><a href="#cb1-108" aria-hidden="true" tabindex="-1"></a><span class="fu"># Conclusion and Discussion</span></span>
<span id="cb1-109"><a href="#cb1-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-110"><a href="#cb1-110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-111"><a href="#cb1-111" aria-hidden="true" tabindex="-1"></a>LLMs hold significant potential to function as autonomous agents in the real world. Limitations in certain areas can be offset by integrating specialized tools that already excel in those domains. In particular, access to financial resources could enable an LLM to expand its capabilities into the full spectrum of human skills and knowledge.</span>
<span id="cb1-112"><a href="#cb1-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-113"><a href="#cb1-113" aria-hidden="true" tabindex="-1"></a>While some argue that new high-quality data will become scarce, the methods for training LLMs will continue to evolve. Approaches such as reinforcement learning and human-in-the-loop training can still generate substantial amounts of valuable training data. Moreover, data produced collaboratively by humans and LLMs may prove useful, and we may see an increasing abundance of such hybrid datasets.</span>
<span id="cb1-114"><a href="#cb1-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-115"><a href="#cb1-115" aria-hidden="true" tabindex="-1"></a>Finally, advancements in reinforcement learning and related techniques have the potential to further enhance LLMs’ abilities in reasoning, strategy, and logical thinking, bringing them closer to truly autonomous and adaptable agents.</span>
<span id="cb1-116"><a href="#cb1-116" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-117"><a href="#cb1-117" aria-hidden="true" tabindex="-1"></a>The scope of LLM research is vast, and we have addressed only a small portion of it — omitting, for example, multimodal models. In my view the potential of LLMs is far from fully realized, and significant advancements are likely to emerge in the near future.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p><span class="faux-block">© 2024 Jens Müller</span></p>
</div>   
    <div class="nav-footer-center">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
    <a class="nav-link" href="../../impressum/index.html">
<p>Impressum</p>
</a>
  </li>  
</ul>
    </div>
    <div class="nav-footer-right">
<p><span class="faux-block"><a href="https://github.com/XarwinM/jens-dot-io">View source on GitHub</a></span></p>
</div>
  </div>
</footer>




</body></html>